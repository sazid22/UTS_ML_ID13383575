{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_13383575.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazid22/UTS_ML_ID13383575/blob/master/A1_13383575.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjYfWKocU0Au",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on Generative Adversarial Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztuci5wPiOQ7",
        "colab_type": "text"
      },
      "source": [
        "##Student Information:\n",
        "###Name - Sazid Al Ahsan\n",
        "###Student ID - 13383575\n",
        "###Github Link of Repository - \n",
        "###Colab Link - https://colab.research.google.com/drive/1SCzuvfy7KpyRn-0tM2p_h9DcrSALZ1mV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI3u8CcHRTdm",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x7ueUjlUoW5",
        "colab_type": "text"
      },
      "source": [
        "## Content\n",
        "In the paper \"Generative Adversarial Network\", the authors have proposed a new model that has opened new possibilities in the research of generative modeling. Discriminative models have been a popular research topic in the field of machine learning, but this is the leading publication on generative models using the adversarial process. What a generative model does is they create new data points from given training data points. Previously it was done by mapping from X to Y where X is the training data space and Y is the corresponding data points in the generated data space. This paper provides a new way of generating this fake dataspace. Rather than doing mapping, the authors provide a framework consisting of a generative model and a discriminative model. The generator creates datapoint given any distribution and discriminator identifies if the data is from a real distribution or it has been fakely generated. This is where the term \"adversarial\" comes handy, as discriminator identifies between the fake and real, the generator produces better output through the process by learning on the basis of the outcome of the discriminator. The goal of this generative model is as such that the discriminator predicts as low as possible approximately half of the fake points and the real point.  \n",
        "\n",
        "As mentioned earlier, the generative model has been a field of interest for machine learning pioneer, there has been some issue. This is mostly with the probability approximation where it might require to use less accurate maximum likelihood estimation or models like Markov chains is used to calculate the probability. This makes the approximation very complex as well as inaccurate. Ian Goodfellow and his team stepsides these difficulties and propose a new process for the estimation calculation of the generative model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggf4Mi4Wf2v2",
        "colab_type": "text"
      },
      "source": [
        "##Innovation\n",
        "This research on generative modeling is very innovative for various reasons. \n",
        "\n",
        "*   As mentioned, the earlier papers relied on maximizing the likelihood, this paper proposes the idea of adversarial training. Whereas previous generative models for example deep directed graphical models are not able to calculate the probability distribution of the dataset, p(x) and later using error-prone estimation methods, GAN completely avoids this explicit estimation. Rather it uses binary classification feedback from the discriminator to train the generator.  \n",
        "*  Whereas the previous models used a method like Markov Chains to do estimation, this also made the process slow and computationally complex. This paper uses the feed-forward network which works from latent space Z to data space X to create fake data which is much simpler than those of the previous models. \n",
        "*   As the proposed model is a feedforward model, the generation is not dependent on observations from previous time steps. As a result, the GAN model can parallelize the generation process which makes it faster. Auto-Regressive Models like PixelCNN where they work on an initially imposed model are not able to do this parallel generation. \n",
        "*   This paper introduces two loss functions. One is Minimax loss and another is non-saturated loss. The later is advised by the authors to practice and they implemented the later in this paper. What non-saturated loss is that rather than the data generated having a high probability of being real, the generator tries to decrease the alternative possibility.\n",
        "\n",
        "<img src=\"https://github.com/sazid22/UTS_ML_ID13383575/blob/master/1.jpg\" width=\"100\"/>\n",
        "\n",
        "*    This paper is innovative for the application of generative models. It has shown the direction in many fields where generative models can be used and help improve the existing field. From artistic use to field like medical images GAN has provided a new direction. As it is computationally less complex and faster, GAN can perform better and less error-prone than existing generative models before that. \n",
        "\n",
        "Finally, this paper has paved a new direction for researchers among scholars. There have been numerous publications and repositories on GAN and its variants. It can be said that with existing works on generative models, this paper contributes in a great way in the field of machine learning with its innovation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UjtNXLO-Og",
        "colab_type": "text"
      },
      "source": [
        "## Technical Quality\n",
        "This paper was published in NIPS 2014, which is one of the leading conferences on machine learning. Overall the paper has high technical quality. The description of the model was very well described. They have explained their novelty with a good explanation. Mathematical equations were provided so that it is easy to grasp the idea of their hypothesis as well as the provided proof of these equations. They did not limit this proof with their own findings but provided comparisons with existing divergence models and explained how their model is less complex and computationally superior than the existing generative model. In the paper, they provided an algorithm and pseudocode of this algorithm which makes the way for implementing the model. They also derived two propositions from the algorithm and showed their proof mathematically using existing divergence methods and described the proposition's optimality.\n",
        "\n",
        "Even though the theoretical part of this paper is good, there are issues with an experiment conducted in parallel to technical writing. The number of experiment conducted is only 3 and these were conducted in a very limited environment. Even the comparison was not shown for all 3 experiments, as the authors went to show a comparison between 2 experiments. So this arises a reliability issue of the model proposed. Another issue with the paper is that they used log-likelihood estimation to evaluate their methods. Log-likelihood has a tendency to show high variance in the result which arises questions in terms of reliability. \n",
        "\n",
        "Another point to mention is that the authors went for only qualitative comparison. Qualitative can be idiosyncratic sometimes as it varies from the experimental setup. But the authors have mentioned this issue and they have mentioned they went for qualitative comparison to show that GANs are on par with the existing generative models in terms of complexity and speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVBjDmGl2TxF",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor\n",
        "The application domain of GAN has not been described in this paper. But it is pretty admissible that GANs can be used in any type of application where the generative model is used. Since the publication of this paper, there has been a lot of research and implementation where we can see the application of that. Progressive-Growing GANs is one of the first GAN models that has been used commercially. This GAN architecture was released by Nvidia which shows great results in image synthesis. What Progressive-Growing GAN does is it can create very high-resolution fake images. It was a big jump from low-resolution images like CIFAR-10 where the resolution is $32^2$ whereas this architecture can generate a facial image that has a resolution of $1024^2$.\n",
        "\n",
        "GAN can also generate videos. This project is done by MIT students. They taught two neural networks over two million videos. What their architecture does is given any image, it can generate the next 2 seconds. What they did was base on a good intention, but GAN has been used in creating fake videos later on. Last year Deepfake videos were made with an intention to create a hoax and fake news. This shows GANs can be used to gain spiteful purposes.\n",
        "\n",
        "In a brief, this paper has introduced scholars with a great opportunity to work on adversarial learning. Generative models have been there but a new door was opened for everybody. The amount of papers, actually great quality papers on GANs being published since 2014 has increased each year. Various kind of GAN architecture for different purposes has been introduced. Not just variants, optimization of GAN has also been a topic of works for researchers. Semi-supervised learning has become a point of the extensive researcher after authors of this paper proposed as future work. Moreover, many well-known universities have begun courses on GAN and big companies are also working on implementing GAN in various applications and research. So it can be said GAN has created a lot of buzz in the world of machine learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ysgt8NZ8Tj",
        "colab_type": "text"
      },
      "source": [
        "##Presentation\n",
        "The overall presentation of this paper is very good. The paper does not have a vague idea and the representation is succinct. The abstract of the paper provides the idea of the paper very clearly without any jargon and represents the idea of what this paper proposes. The introduction provides us with what they are going to do and more formally presents the novelty of the paper. In the literature review section, they discussed existing methods of generative models and their disadvantages and how their work is going to overcome these. In the next section, \"Adversarial Nets\", the authors gave a brief introduction of adversarial learning and provided the mathematical equation of that which is indicative of a good presentation goal. The next section, \"Theoretical Result\" is the strongest part of this paper. The provided algorithm how the method will run then they provide theorem and propositions over them and has provided the proof of those which are really great and mathematically very intuitive. Then they showed their experiment. It was a weak part of the paper as they practically implemented the idea in a very narrow way and only three experiments were done. So it was a weak part of the paper but as an inaugural paper on adversarial learning, it somehow can be overlooked and taken as a learning for future experiments. Lastly, they provided an open-ended idea for future works and the time my report is being written I can see on the internet a lot of those ideas are now being worked on. The authors also provided the Github repository of all their code but there is a little description of those codes and the repository was not well maintained. But overall this is a great paper and provides direction for machine learning practitioners. "
      ]
    }
  ]
}