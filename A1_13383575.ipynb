{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_13383575.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazid22/UTS_ML_ID13383575/blob/master/A1_13383575.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjYfWKocU0Au",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on Generative Adversarial Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI3u8CcHRTdm",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x7ueUjlUoW5",
        "colab_type": "text"
      },
      "source": [
        "## Content\n",
        "In the paper \"Generative Adversarial Network\", the authors have proposed a new model that has opened new possibilities in the research of generative modeling. Discriminative models have been a popular research topic in the field of machine learning, but this is the leading publication on generative models using the adversarial process. What a generative model does is they create new data points from given training data points. Previously it was done by mapping from X to Y where X is the training data space and Y is the corresponding data points in the generated data space. This paper provides a new way of generating this fake dataspace. Rather than doing mapping, the authors provide a framework consisting of a generative model and a discriminative model. The generator creates datapoint given any distribution and discriminator identifies if the data is from a real distribution or it has been fakely generated. This is where the term \"adversarial\" comes handy, as discriminator identifies between the fake and real, the generator produces better output through the process by learning on the basis of the outcome of the discriminator. The goal of this generative model is as such that the discriminator predicts as low as possible approximately half of the fake points and the real point.  \n",
        "\n",
        "As mentioned earlier, the generative model has been a field of interest for machine learning pioneer, there has been some issue. This is mostly with the probability approximation where it might require to use less accurate maximum likelihood estimation or models like Markov chains is used to calculate the probability. This makes the approximation very complex as well as inaccurate. Ian Goodfellow and his team stepsides these difficulties and propose a new process for the estimation calculation of the generative model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggf4Mi4Wf2v2",
        "colab_type": "text"
      },
      "source": [
        "##Innovation\n",
        "This research on generative modeling is very innovative for various reasons. \n",
        "\n",
        "*   As mentioned, the earlier papers relied on maximizing the likelihood, this paper proposes the idea of adversarial training. Whereas previous generative models for example deep directed graphical models are not able to calculate the probability distribution of the dataset, p(x) and later using error-prone estimation methods, GAN completely avoids this explicit estimation. Rather it uses binary classification feedback from the discriminator to train the generator.  \n",
        "*  Whereas the previous models used a method like Markov Chains to do estimation, this also made the process slow and computationally complex. This paper uses the feed-forward network which works from latent space Z to data space X to create fake data which is much simpler than those of the previous models. \n",
        "*   As the proposed model is a feedforward model, the generation is not dependent on observations from previous time steps. As a result, the GAN model can parallelize the generation process which makes it faster. Auto-Regressive Models like PixelCNN where they work on an initially imposed model are not able to do this parallel generation. \n",
        "*   This paper introduces two loss functions. One is Minimax loss and another is non-saturated loss. The later is advised by the authors to practice and they implemented the later in this paper. What non-saturated loss is that rather than the data generated having a high probability of being real, the generator tries to decrease the alternative possibility.\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/file/d/1AZNknO7i0Z2V2aRnomGbS2Jp8Y9Vucdy/view' />\n",
        "<figcaption>Equation of Minmax Loss and Non-Saturationg Loss</figcaption></center>\n",
        "</figure>\n",
        "*    This paper is innovative for the application of generative models. It has shown the direction in many fields where generative models can be used and help improve the existing field. From artistic use to field like medical images GAN has provided a new direction. As it is computationally less complex and faster, GAN can perform better and less error-prone than existing generative models before that. \n",
        "\n",
        "Finally, this paper has paved a new direction for researchers among scholars. There have been numerous publications and repositories on GAN and its variants. It can be said that with existing works on generative models, this paper contributes in a great way in the field of machine learning with its innovation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UjtNXLO-Og",
        "colab_type": "text"
      },
      "source": [
        "## Technical Quality\n",
        "This paper was published in NIPS 2014, which is one of the leading conferences on machine learning. Overall the paper has high technical quality. The description of the model was very well described. They have explained their novelty with a good explanation. Mathematical equations were provided so that it is easy to grasp the idea of their hypothesis as well as the provided proof of these equations. They did not limit this proof with their own findings but provided comparisons with existing divergence models and explained how their model is less complex and computationally superior than the existing generative model. In the paper, they provided an algorithm and pseudocode of this algorithm which makes the way for implementing the model. They also derived two propositions from the algorithm and showed their proof mathematically using existing divergence methods and described the proposition's optimality. "
      ]
    }
  ]
}